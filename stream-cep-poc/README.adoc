= POC on Streaming & CEP with Strimzi and BRMS
:toc:

== Configure OCP Cluster Environment & KAFKA Cluster

Read instructions for 

* * link:https://github.com/skoussou/streaming-cep/blob/master/README-Setup-KAFKA-Cluster.adoc[Ephemeral - KAFKA Cluster Setup]
* link:https://github.com/skoussou/streaming-cep/blob/master/README-Setup-Persistent-KAFKA-Cluster.adoc[Persistent - KAFKA Cluster Setup]



== Deploy the applications

=== Create topics

This demo uses 2 topics (*for now*). 
1. The first one named *_bank-user-transactions_* is used by the data generator simulator app _streaming-cep-data-generator-app_ for sending *transactional data object* and by the stream processing app _streaming-cep-stream-processor-app_ for getting such values and processing them. 
2. The second one is the *_bank-rewards_* topic where the stream processing app __streaming-cep-stream-processor-app_ puts the rewards points for each $ in the transaction
3. The third one is *_bank-ops-credit-management_* topic where the stream processing app __streaming-cep-stream-processor-app_ when > 5 transactions in processed in the specified time window sends to increase credit limit

In order to create these topics in the Kafka cluster, the _Topic Operator_ is used by defining a ConfigMap which is read based on the labels

[source,sh]
----
    strimzi.io/kind: topic
    strimzi.io/cluster: my-cluster
----

Running the following command, file containing 3 topic ConfigMaps is deployed to the OpenShift cluster and used by the _Topic Operator_ for creating such topics.

[source,sh]
----
oc create -f ./streaming-cep-stream-processor-app/resources/topics.yml
----

image:images/topics.png["In Stream Realtime CEP",height=356] 

In order to check that the topics are properly created on the Kafka cluster, it's possible to use the `kafka-topics.sh` script  (distributed with Kafka) running it on one of the broker.

[source,sh]
----
oc rsh my-cluster-kafka-0
/opt/kafkabin/kafka-topics.sh --zookeeper localhost:2181[0 this can be also 1, 2 or whichever zookeeper pod rsh in] --list

----

The output of the above command should be something like the following showing the created topics.

[source,sh]
----
bank-ops-credit-management
bank-rewards
bank-user-transactions
----



=== To point an application to the correct cluster

[source,sh]
----
    spec:
      containers:
        - name: streaming-cep
          image: streamingcep/streaming-cep-data-generator-app:latest
          env:
            - name: BOOTSTRAP_SERVERS
              value: "my-cluster-kafka-bootstrap:9092"
----

==== FOR THE DEMONSTRATION AT RHTE 2018 we need
a) Use the *strimzi-persistent* template
b) Further tune KAFKA
c) Create topics (see below) which are relevant to our application

Note that the applications will have to point to the clustered KAFAK service and we do so via a property *BOOTSTRAP_SERVERS* as followes
- name: BOOTSTRAP_SERVERS
              value: "my-cluster-kafka-bootstrap:9092"



## Deploy the consumer application

The consumer application uses Kafka client in order to get messages from the `iot-temperature-max` topic and showing them 
in a Web UI.
It's deployed running following command :

[source,sh]
----
oc create -f ./consumer-app/resources/consumer-app.yml
----

A route is provided in order to access the related Web UI.

![route](images/route.png)

![web ui](images/web_ui.png)

## Deploy the stream application

The stream application uses Kafka Streams API reading from the `iot-temperature` topic, processing its values and then 
putting the max temperature value in the specified time window into the `iot-temperature-max` topic.
It's deployed running following command :

[source,sh]
----
oc create -f ./stream-app/resources/stream-app.yml
----

## Deploy the device application

The device application provides a device simulator which sends temperature values to the `iot-temperature` topic.

[source,sh]
----
oc create -f ./device-app/resources/device-app.yml
----

Once deployed, it starts just one pod simulating one device.

![one device gauge](images/one_device_gauge.png)

it's possible to scale up the number of pods in order to simulate more devices sending temperature values (each one with 
a different and randomly generated id).

![scale up device](images/scale_up_device.png)

Opening the consumer Web UI it's possible to see the "gauges" charts showing the processed max temperature values for all the 
active devices on the left side. The right side is useful to see the log of the incoming messages from devices, showing the 
device id alongside the max temperature value processed by the stream application for such a device.

![more device gauges](images/more_device_gauges.png)

## Clean up

If you want it could be useful to clean up the current deployment deleting all the related resources in terms of Pods, Services, Routes and Deployments.

[source,sh]
----
oc delete all -l app=iot-demo
----

And finally the topic config maps

[source,sh]
----
oc delete cm -l strimzi.io/kind=topic
----





